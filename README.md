# Toxic-Comment-Classification

## Description

Toxic-Comment-Classification is a comprehensive project aimed at identifying and classifying toxic comments into categories such as threats, obscenity, insults, and identity-based hate. The project employs a combination of classical machine learning, deep learning, and transformer-based approaches to build robust models for detecting online toxicity effectively.

## Features

- Classical Machine Learning Models: Logistic Regression, Random Forest, SVM, and GaussianNB for baseline comparisons.

- Deep Learning Implementation: BiLSTM using GloVe embeddings for context-aware toxicity detection.

- Transformer-Based Model: Fine-tuned DistilBERT for multi-label classification, achieving state-of-the-art results.

- Comprehensive data preprocessing pipeline for cleaning and preparing text data.

- Evaluation Metrics: F1-Score, ROC AUC, and Hamming Loss for performance analysis.

- Submission Files: Includes results for all three approaches.

## Dataset

The dataset used in this project is derived from the Kaggle competition Toxic Comment Classification Challenge. It contains labeled data across six toxicity categories.